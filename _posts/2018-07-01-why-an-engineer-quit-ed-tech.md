---
layout: post
title:  "Why an Engineer Quit Ed-Tech"
date:   2018-07-01 18:06:56 -0700
author: raja
categories: jekyll update
---

After nearly three years of working at AltSchool as a software engineer, I quit early March 2018. I had joined with great hesitation, initially quite skeptical of buzzwords like "personalized learning," "micro-schools," and the distance I saw between working for a private-school and the public schools I really wanted to work with.    AltSchool was somewhat unique, I thought, in that there would be fewer barriers between the engineers and the educators, and AltSchool had full control over the classroom. So, we could design a learning environment, not just the software, thus considering all relevant factors.

I had entered ed-tech, not as an experienced educator by any means, but with a lot of 'peripheral' education experience (mentoring, camp counselor, working closely with at-risk youth). I was more exposed than many of my Silicon Valley peers. I couldn't wait to apply what I had learned from my experience and my readings of _Mindstorms_, _How People Learn_, and _Pedagogy of the Oppressed_, and Audrey Watters. I leave disappointed by education technology as a whole to realize any of this potential, because ultimately the business needs of schools conficts with the actual needs of the educators and students. I have no intention to return to this field.

## The Product Is, At Best, A Placebo

AltSchool's product fails to deliver real value to educators, students, or parents. This is well recognized internally. The most optimistic will say that the software is "still a work in progress," which is an effective cover for the unflapping confidence that the company's _product vision_ will be successful, even in spite of consistent feedback showing otherwise. This product vision, while ostensibly aimed to make 'personalized learning' accessible to the masses, was primarily a vehicle for raising greater and greater sums of venture capital funding.

### AltSchool's Product Vision

While the details of AltSchool's vision change quite frequently, the themes are constant. The product is supposed to enable the "AltSchool Learning Cycle," which, when I started, consisted of "Engage," "Evaluate", "Understand", "Plan". We thought of the product as having different points of contact with each of these verbs. 

"Engage" consisted of assigning work to a student's Playlist (a list of assignments). These assignments consisted of a prompt, a cover image, and some way for the student to 'finish' the card: multiple choice questions, free-response questions, a request to upload photos showing the finished product of their work. The assignment could be totally offline, with some documentation done on the part of the student to share what they did, or it could be totally online (watch this video, spend time on Khan Academy). The playlist was supposed to enable personalization by allowing educators to assign work to each student depending on their progress, rather than giving each student the same assignment.

In "Evaluate," educators received the 'finished' assignment from each student, and assessed it against AltSchool's custom learning taxonomy (this was essentially a grouping of Common Core Standards, created because the Common Core has an overwhelming number of standards to cover). Assessments on each objective in the taxonomy were done using a variety of rubrics: most used a standard 4-level "Emerging," "Practicing," "Meeting," "Outstanding" rubric. The "Inbox" was the place where educators could see a list of all assignments from all students in their class, and bulk-assess students on the same assignment quickly.

This assessment data would show up in "Progression," which would help educators "Understand" where each student is at: what have they mastered and what are they struggling with? "Progression" was supposed to take into account ALL of the assessment data available on the student: all assessments done on the AltSchool product, standardized test results like the NWEA MAP test, and data from online learning providers like Khan Academy, Lexia, and DreamBox. The more data the system has on each objective in the taxonomy, the more the system could understand about the student's mastery of that objective. One of the biggest pain points for educators is not having a good idea of where each student in their classroom is, and "Progression" was supposed to be the key to solving that pain point. Another big need "Progression" was supposed to meet is external communication: with parents, and for compliance and accountability purposes.

With this understanding, educators could then "Plan" the next "Unit" of work for their class. This plan could be hand-crafted, or, more desirable, it could be a remix of existing curriculum in the system, perhaps created by a master educator. Each unit is tagged with objectives from the learning taxonomy, and each assignment within it as well. 

With enough data, you can imagine having data on the impact each assignment has on a student's mastery of each objective in the learning taxonomy. You could imagine having smart recommendations made to the teacher on what their students need to work on next, that would target exactly what each student was struggling on. This vision isn't unique to AltSchool by any means, but is in fact fairly common across the ed-tech space. Bill Gates outlines a vision quite similar to it in his [2013 SXSW Keynote Address](https://www.youtube.com/watch?v=5MJxOIMVS5A).

This vision, while seemingly utopian in its ideal of giving each student a personalized tutor, is lacking in several respects. Larry Berger, former CEO of another ed-tech startup, Amplify, [articulated the key components](https://blogs.edweek.org/edweek/rick_hess_straight_up/2018/02/a_confession_and_a_question_on_personalized_learning.html) of the system described by this vision as: the map of learning (corresponding to the objectives in AltSchool's learning taxonomy, or to the Common Core), the measurements to understand where you are in the map, and the library of learning objects to move students from one point on the map to another. With this articulation, he observes: "Here's the problem: The map doesn't exist, the measurement is impossible, and we have, collectively, built only 5% of the library." I agree with this on the whole.

Audrey Watters has written extensively about the problems with student agency posed by these systems, which I think needs to be given more weight here. This system leaves no room for student agency to shape the learning experience. [â€¦] nor does it consider the benefits of group learning. Individualization, while convenient for measurement, does not accurately reflect learning conditions in the classroom. Personalization [is framed](http://blogs.edweek.org/edweek/rick_hess_straight_up/2018/04/a_response_to_larry_bergers.html) as escaping the prison of "teaching same-aged groups of students the same thing-and all in the same way."

This vision also lacks integration with progressive pedagogy and learning sciences. In constructivism, learning is an active process done by the learner: knowledge is not a commodity to be transmitted, but an actively built experience, individually or collectively. These experiences could presumably be represented in the assignments, but (what a student experiences cannot be controlled; the system prefers each item of content to have a known output on a minute thing for it to be measurable and on a point in the map; representation of experience in the system is impoverished - could point to offline prompts, but again system encourages more to be online )

Lack of social or political consideration is another key issue with this vision.

Ultimately, the vision is more a tool of convenience: it sells, and one reason it sells is the pain points coming from accountability. On joining, I challenged this vision, but found that very few people were interested in considering alternatives.

Granted, this vision has changed in the past year, from being the driver of learning to being an assistant for the teacher. The thinking now is to scaffold progressive practices. But, the product would have to make a fundamental change to enable that, to the extent that it is even possible. And, to what extent is it possible to scaffold practice? 

### The Product Today

As problematic as the vision itself is, the reality is even more fraught with issues. The product is not more than a glorified to-do list (for students) that educators can publish to. In truth, educators and students spend inordinate amounts of time putting data into the system (in the form of assignments, assessments, pictures), but receive very little value out of the system. Educators frequently resorted to exporting the data out of the system to create their own spreadsheet system for progress updates, for parent communications, and for transcripts. Educators preferred putting their data outside of the platform, but would be coerced occasionally to put the data back in to the platform. Some of these issues have improved in the past year, but not to a meaningful degree.

When I first joined, I was put on the "Progression" product. At the time, we had our first prototype being used by educators. And educators _hated_ it. We hadn't yet developed an internal learning taxonomy, so we used Common Core. For each subject, we had grade level for columns, and "domains" (e.g., "Operations and Algebraic Thinking") for rows. The cells were filled based on mastery (if 100% of the standards were mastered, then the cell was entirely green. If 50%, then half the cell was green, the other half was orange or grey, depending on whether they had had an assessment or not). One educator-turned-engineer called it the "steady march of green." The algorithm for calculating mastery of each standard was totally opaque to educators. There was NO notion of time. Educators routinely complained that they didn't see the point in this product, that they were getting 0 value out of it.

AltSchool, however, was determined to press forward. "Progression" was the lynchpin in its product strategy, in achieving the vision described above. It needed stability in this product, and evolution in the product, both to 'learn' more about what the issues were (which, I thought, were clear, given the issues with the vision). The feedback I heard from educators contradicted in many ways the direction we were going. Our product was essentially an extension of the supposed "traditional" education we were trying to disrupt, simply made digital. 

We had a meeting to discuss the future of "Progression," which, to my surprise, was less about identifying a clear need and building from that, and more about how we might be able to incorporate more data sources, and how we should bring to bear machine learning on the problem, as soon as possible. I insisted that we start from the simplest thing to help us identify the real need: simply present the educators the raw data they put in to the system, since we had little understanding of how they would use the data. I was ignored (though, now, 2 years later, AltSchool is building precisely this simplified view). We only knew that they should put it in the system, and that, eventually, we would use machine learning to accomplish the product vision. Having worked on machine learning systems before, and having spent a lot of time analyzing data, I knew that good analysis requires having a clear perspective on what purpose the data is being collected for, what questions are supposed to be answered. The details, it seemed, didn't matter.

## AltSchool Put Satisfying Investors Over Real Progress 

Why did the details not matter? AltSchool had a strict product development cycle, to make sure that we were all rowing in the same direction. This was apparently more important than making sure we were rowing in the right direction. The priority was always to deliver on time, at a predictable schedule. This made sense from an operational standpoint, since educators can't be distracted by new features until big breaks like winter break, spring break, or summer. But the direction we were rowing was ultimately what would retain the interest of investors, it seemed. Just when voice was getting hot in the VC world, management was asking engineers to think about how we might incorporate voice assistant systems. When IoT was hot, we were spending millions installing cameras and mics to get a $360{\circ}$ picture of the classroom. "We can use face recognition to analyze who likes working with who!" one product manager told me. Was that really the critical problem to be solved?

To be fair to AltSchool, it had taken far more money than it could ever hope to make back. When I joined, I was told that the investors were not looking for an early exit or acquisition, but instead were 'here for the long run'. The CEO spoke of being here for 10 years. It has been around 5 now, so that's something. But the organization couldn't figure out whether it was working on the long term or the short term. Investors seemed to be prioritizing the short term, which is why AltSchool's business strategy shifted away from micro-schools towards the standard SaaS model. 
